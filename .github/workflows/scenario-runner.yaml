name: Run AVER Assessment

on:
  workflow_dispatch:
    inputs:
      agent_model:
        description: 'Model to test'
        required: true
        default: 'anthropic/claude-3.5-sonnet'
        type: choice
        options:
          - anthropic/claude-opus-4.5
          - openai/gpt-5.2
          - google/gemini-2.5-flash
          - google/gemini-2.5-pro
          - google/gemini-3-pro-preview
      num_tasks:
        description: 'Number of tasks'
        required: false
        default: '10'
        type: string

env:
  OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
  AGENT_MODEL: ${{ github.event.inputs.agent_model || 'anthropic/claude-3.5-sonnet' }}

jobs:
  assessment:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      packages: read
      pull-requests: write

    steps:
      - uses: actions/checkout@v4

      - name: Run AgentBeats scenario
        run: |
          echo "Running AVER assessment"
          echo "Model: $AGENT_MODEL"
          echo "Tasks: ${{ github.event.inputs.num_tasks || '10' }}"

          # AgentBeats CLI would go here:
          # ab run scenario.toml

          # For now, placeholder for local testing
          echo "Assessment would run here via AgentBeats platform"

      - name: Save results
        run: |
          mkdir -p results
          TIMESTAMP=$(date +%Y%m%d_%H%M%S)
          MODEL_NAME=$(echo "$AGENT_MODEL" | tr '/' '_')
          echo '{"status": "placeholder", "model": "'"$AGENT_MODEL"'"}' > "results/${MODEL_NAME}_${TIMESTAMP}.json"
